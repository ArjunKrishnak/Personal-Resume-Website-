[{"categories":null,"contents":"In this Work, we introduce a video hashing method for scalable video segment copy detection. The objective of video segment copy detection is to find the video (s) present in a large database, one of whose segments (cropped in time) is a (transformed) copy of the given query video. This transformation may be temporal (for example frame dropping, change in frame rate) or spatial (brightness and contrast change, addition of noise etc.) in nature although the primary focus of this report is detecting temporal attacks. The video hashing method proposed by us uses a deep learning neural network to learn variable length binary hash codes for the entire video considering both temporal and spatial features into account. This is in contrast to most existing video hashing methods, as they use conventional image hashing techniques to obtain hash codes for a video after extracting features for every frame or certain key frames, in which case the temporal information present in the video is not exploited. Our hashing method is specifically resilient to time cropping making it extremely useful in video segment copy detection. Experimental results obtained on the large augmented dataset consisting of around 25,000 videos with segment copies demonstrate the efficacy of our proposed video hashing method.\n","permalink":"https://arjunkrishnak.github.io/publications/vscd/","tags":["Machine Learning","Deep Learning","Pytorch","Python","OpenCV"],"title":"Video segment copy detection"},{"categories":null,"contents":"Worked and experimented with CLR algorithm which is implemented in Keras that uses cyclical learning rates to train deep neural networks.\n","permalink":"https://arjunkrishnak.github.io/projects/contributions/cyclical_lr/","tags":["Machine Learning","Deep Learning","TensorFlow","Python"],"title":"Cyclical Learning Rate (CLR)"},{"categories":null,"contents":"This app focuses on quickly creating colorful flowcharts , UMLs, and mindmaps. All of the app elements are gesture-based and intuitive making it very easy to use. This app also features an endless canvas that the user can pan and zoom.\n","permalink":"https://arjunkrishnak.github.io/projects/creations/express_flowcharts/","tags":["Android SDK","Android Studio","Java"],"title":"Express flowcharts android app"},{"categories":null,"contents":"expresswiki.ml is a website that i have created which harness the power of AI to provide intelligent reading exprience to the reader. It is build using the MERN stack and is deployed on an AWS instance\n","permalink":"https://arjunkrishnak.github.io/projects/creations/express_wiki/","tags":["React","MongoDB","NodeJS","JavaScript","AWS","Python","Natural Language Processing","Machine Learning"],"title":"Express Wiki"},{"categories":null,"contents":"The​ ​application​ ​is​ ​basically​ ​a​ ​functional​ ​Google​ ​Chrome​ ​Extension​ ​that generates​ ​a​ ​caption​ ​for​ ​an​ ​image​ ​which​ ​describes​ ​what​ ​is​ ​contained​ ​in​ ​the image.​ ​The​ ​image​ ​captioning​ ​is​ ​done​ ​by​ ​a​ ​deep​ ​learning​ ​network​ ​which​ ​runs​ ​on a​ ​cloud​ ​server (Heroku).​ ​The​ ​caption​ ​generated​ ​is​ ​converted​ ​into​ ​speech​ ​by JavaScript’s​ ​Web​ ​Speech​ ​AP (SpeechSynthesisUtterance​ ​API).\n","permalink":"https://arjunkrishnak.github.io/projects/creations/chrome_extension_using_rcnn/","tags":["Python","JavaScript","Deep Learning","Computer Vision","Machine Learning"],"title":"Google chrome extension to caption images using RCNN"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026quot;HTML\u0026quot;, \u0026quot;JSON\u0026quot;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026quot;contents\u0026quot;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026quot;tags\u0026quot;:{{ .Params.tags | jsonify }}{{end}}, \u0026quot;categories\u0026quot; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026quot;title\u0026quot;, \u0026quot;contents\u0026quot;, \u0026quot;tags\u0026quot;, \u0026quot;categories\u0026quot; ] ","permalink":"https://arjunkrishnak.github.io/search/","tags":null,"title":"Search Results"},{"categories":null,"contents":"Proposed a combination of MSER(Maximally Stable Extremal Regions) detection followed by SWT(Stroke Width Transform) to improve the accuracy of text localization.\n","permalink":"https://arjunkrishnak.github.io/projects/contributions/text_detection_in_natural_scenes/","tags":["OpenCV","Python","Computer Vision","Machine Learning","Image processing"],"title":"Text detection in natural scenes"}]